{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part A: Fitting multiple regression predicting sales using price, urban, and US.\n",
    "\n",
    "Part B: Holding all variables constant each 1 dollar increase in price is expected to drop the predicted sales by 0.054 units. Being in an urban area vs. a non-urban area decreases sales by 0.022 units. Being in the US vs not being in the US increases sales by 1.201 units.\n",
    "\n",
    "Part C: Predicted Sales = 13.043 + -0.054 * (Price) + -0.022 * (Urban) + 1.201 * (US)\n",
    "\n",
    "Part D: Reject the null hypothesis for X1 (Price) and X3 (US). There is not sufficient evidence to reject the null hypothesis B = 0 for the predictor urban. \n",
    "\n",
    "Part E: Constructing model dropping X2 or Urban given non-significant \n",
    "\n",
    "Part F: The model from part A has an adjusted R-squared value of 0.234 and the model from part e has an adjusted R-squared value of 0.235. Therefore, for model A 23.4 percent of the variation in sales is explained by the variation in price, urban, and US.  While 23.5 percent of the variation in sales is explained by the variation in price, and US. Neither model is fits the data well, however, the simpler model appears to be slightly better. \n",
    "\n",
    "Part G: For Price the 95 percent confidence interval is [-0.065,-0.044] and for US it is [0.692,1.708]. Note 0 is not in the interval.\n",
    "\n",
    "Part H: The p-values for omnibus and jarque-bera indicate that residuals do not significantly deviate from normality i.e. we fail to reject the null hypothesis that the residuals are normally distributed which suggests there is not strong evidence of outliers. Also the kurtosis value is 2.895 which is very close to 3 indicating no extreme tails. There are 20 high leverage values present. These are assigned by the equation 2(# predictors + 1) / (# observations). Therefore any leverage value greater than 0.015 is considered high leverage. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading carseats data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sales  CompPrice  Income  Advertising  Population  Price ShelveLoc  Age  \\\n",
      "0   9.50        138      73           11         276    120       Bad   42   \n",
      "1  11.22        111      48           16         260     83      Good   65   \n",
      "2  10.06        113      35           10         269     80    Medium   59   \n",
      "3   7.40        117     100            4         466     97    Medium   55   \n",
      "4   4.15        141      64            3         340    128       Bad   38   \n",
      "\n",
      "   Education Urban   US  \n",
      "0         17   Yes  Yes  \n",
      "1         10   Yes  Yes  \n",
      "2         12   Yes  Yes  \n",
      "3         14   Yes  Yes  \n",
      "4         13   Yes   No  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "carseats = pd.read_csv(\"Carseats.csv\")\n",
    "\n",
    "print(carseats.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part A: Fitting multiple regression predicting sales using price, urban, and US.\n",
    "\n",
    "Part B: Holding all variables constant each 1 dollar increase in price is expected to drop the predicted sales by 0.054 units. Being in an urban area vs. a non-urban area decreases sales by 0.022 units. Being in the US vs not being in the US increases sales by 1.201 units.\n",
    "\n",
    "Part C: Predicted Sales = 13.043 + -0.054 * (Price) + -0.022 * (Urban) + 1.201 * (US)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sales =  13.043468936764892  +  -0.054458849177582175 * (Price)  +  -0.021916150814141 * (Urban)  +  1.2005726977941158 * (US)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "#reference level will be No\n",
    "carseats['Urban'] = carseats['Urban'].map({'No': 0, 'Yes': 1})\n",
    "carseats['US'] = carseats['US'].map({'No': 0, 'Yes': 1})\n",
    "\n",
    "X = carseats[['Price', 'Urban', 'US']].values\n",
    "y = carseats[['Sales']].values\n",
    "\n",
    "\n",
    "MLRModel = LinearRegression()\n",
    "\n",
    "MLRModel.fit(X, y)\n",
    "\n",
    "print(\n",
    "    \"Predicted Sales = \",\n",
    "    MLRModel.intercept_[0],\n",
    "    \" + \",\n",
    "    MLRModel.coef_[0][0],\n",
    "    \"* (Price)\",\n",
    "    \" + \",\n",
    "    MLRModel.coef_[0][1],\n",
    "    \"* (Urban)\",\n",
    "    \" + \",\n",
    "    MLRModel.coef_[0][2],\n",
    "    \"* (US)\",\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Metrics\n",
    "\n",
    "Part D: Reject the null hypothesis for X1 (Price) and X3 (US). There is not sufficient evidence to reject the null hypothesis B = 0 for the predictor urban. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.239\n",
      "Model:                            OLS   Adj. R-squared:                  0.234\n",
      "Method:                 Least Squares   F-statistic:                     41.52\n",
      "Date:                Mon, 03 Mar 2025   Prob (F-statistic):           2.39e-23\n",
      "Time:                        17:27:35   Log-Likelihood:                -927.66\n",
      "No. Observations:                 400   AIC:                             1863.\n",
      "Df Residuals:                     396   BIC:                             1879.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         13.0435      0.651     20.036      0.000      11.764      14.323\n",
      "x1            -0.0545      0.005    -10.389      0.000      -0.065      -0.044\n",
      "x2            -0.0219      0.272     -0.081      0.936      -0.556       0.512\n",
      "x3             1.2006      0.259      4.635      0.000       0.691       1.710\n",
      "==============================================================================\n",
      "Omnibus:                        0.676   Durbin-Watson:                   1.912\n",
      "Prob(Omnibus):                  0.713   Jarque-Bera (JB):                0.758\n",
      "Skew:                           0.093   Prob(JB):                        0.684\n",
      "Kurtosis:                       2.897   Cond. No.                         628.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "#this is adding constant term for intercept\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the regression model\n",
    "modelmetrics = sm.OLS(y, X).fit()\n",
    "\n",
    "# Show Model Summary\n",
    "print(modelmetrics.summary())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part E: Constructing model dropping X2 or Urban given non-significant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sales =  13.03079275461576  +  -0.054477632479787264 * (Price)  +  1.1996429432266784 * (US)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X = carseats[['Price', 'US']].values\n",
    "y = carseats[['Sales']].values\n",
    "\n",
    "\n",
    "MLRModel = LinearRegression()\n",
    "\n",
    "MLRModel.fit(X, y)\n",
    "\n",
    "print(\n",
    "    \"Predicted Sales = \",\n",
    "    MLRModel.intercept_[0],\n",
    "    \" + \",\n",
    "    MLRModel.coef_[0][0],\n",
    "    \"* (Price)\",\n",
    "    \" + \",\n",
    "    MLRModel.coef_[0][1],\n",
    "    \"* (US)\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simpler model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.239\n",
      "Model:                            OLS   Adj. R-squared:                  0.235\n",
      "Method:                 Least Squares   F-statistic:                     62.43\n",
      "Date:                Mon, 03 Mar 2025   Prob (F-statistic):           2.66e-24\n",
      "Time:                        18:11:57   Log-Likelihood:                -927.66\n",
      "No. Observations:                 400   AIC:                             1861.\n",
      "Df Residuals:                     397   BIC:                             1873.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         13.0308      0.631     20.652      0.000      11.790      14.271\n",
      "x1            -0.0545      0.005    -10.416      0.000      -0.065      -0.044\n",
      "x2             1.1996      0.258      4.641      0.000       0.692       1.708\n",
      "==============================================================================\n",
      "Omnibus:                        0.666   Durbin-Watson:                   1.912\n",
      "Prob(Omnibus):                  0.717   Jarque-Bera (JB):                0.749\n",
      "Skew:                           0.092   Prob(JB):                        0.688\n",
      "Kurtosis:                       2.895   Cond. No.                         607.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "There are 20 high leverage values.\n"
     ]
    }
   ],
   "source": [
    "#this is adding constant term for intercept\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the regression model\n",
    "modelmetrics = sm.OLS(y, X).fit()\n",
    "\n",
    "# Show Model Summary\n",
    "print(modelmetrics.summary())\n",
    "\n",
    "\n",
    "# Compute influence measures\n",
    "influence = modelmetrics.get_influence()\n",
    "\n",
    "# leverage values \n",
    "leverage = influence.hat_matrix_diag\n",
    "\n",
    "# 2(predictors+1) / (no. observations) gives 0.015 anything greater is considered high\n",
    "high_leverage_count = sum(leverage > 0.015)\n",
    "print(\"There are\",high_leverage_count, \"high leverage values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part F: The model from part A has an adjusted R-squared value of 0.234 and the model from part e has an adjusted R-squared value of 0.235. Therefore, for model A 23.4 percent of the variation in sales is explained by price, urban, and US.  While 23.5 percent of the variation in sales is explained by price, and US. Neither model is fits the data well, however, the simpler model appears to be slightly better. \n",
    "\n",
    "Part G: For Price the 95 percent confidence interval is [-0.065,-0.044] and for US it is [0.692,1.708]. Note 0 is not in the interval.\n",
    "\n",
    "Part H: The p-values for omnibus and jarque-bera indicate that residuals do not significantly deviate from normality i.e. we fail to reject the null hypothesis that the residuals are normally distributed which suggests there is not strong evidence of outliers. Also the kurtosis value is 2.895 which is very close to 3 indicating no extreme tails. There are 20 high leverage values present. These are assigned by the equation 2(# predictors + 1) / (# observations). Therefore any leverage value greater than 0.015 is considered high leverage. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
